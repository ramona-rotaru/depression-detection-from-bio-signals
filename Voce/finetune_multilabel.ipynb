{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\envs\\labplnta\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torchaudio\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from transformers import AutoConfig, Wav2Vec2Processor, Wav2Vec2FeatureExtractor\n",
    "from transformers import HubertModel, HubertConfig, Wav2Vec2Processor\n",
    "import torch.nn as nn\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4033, 112000)\n",
      "(4033,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('./data_severity.npy', allow_pickle=True)\n",
    "labels = np.load('./labels_severity.npy', allow_pickle=True)\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"facebook/hubert-base-ls960\"\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name_or_path,)\n",
    "target_sampling_rate = feature_extractor.sampling_rate\n",
    "print(f\"The target sampling rate: {target_sampling_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=33, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3226, 112000) (3226,)\n",
      "(807, 112000) (807,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "y_train = torch.nn.functional.one_hot(torch.tensor(y_train), num_classes=5)\n",
    "y_test = torch.nn.functional.one_hot(torch.tensor(y_test), num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3226, 5]) torch.Size([807, 5])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00234985 -0.00268555 -0.00134277 ... -0.00878906 -0.00805664\n",
      " -0.00747681]\n",
      "[ 1.2207031e-04  1.2207031e-04  6.1035156e-05 ... -2.9602051e-03\n",
      " -3.4484863e-03 -4.0588379e-03]\n",
      "3226 807\n"
     ]
    }
   ],
   "source": [
    "#create a list of arrays for the training data\n",
    "train_data = []\n",
    "for i in range(len(x_train)):\n",
    "    train_data.append(x_train[i])\n",
    "    \n",
    "#create a list of arrays for the testing data\n",
    "test_data = []\n",
    "for i in range(len(x_test)):\n",
    "    test_data.append(x_test[i])\n",
    "    \n",
    "print(train_data[0])\n",
    "print(test_data[0])\n",
    "\n",
    "print(len(train_data), len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_values'])\n",
      "dict_keys(['input_values'])\n",
      "[-0.12088266 -0.13840723 -0.06830896 ... -0.4570358  -0.41880038\n",
      " -0.38853067]\n"
     ]
    }
   ],
   "source": [
    "features_train = feature_extractor(train_data, sampling_rate=target_sampling_rate)\n",
    "features_test = feature_extractor(test_data, sampling_rate=target_sampling_rate)\n",
    "\n",
    "print(features_train.keys())\n",
    "print(features_test.keys())\n",
    "print(features_train['input_values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([0, 0, 0, 1, 0]), tensor([0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 0, 1, 0]), tensor([0, 1, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 0, 1, 0]), tensor([0, 1, 0, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([0, 0, 0, 1, 0]), tensor([0, 0, 0, 1, 0]), tensor([0, 1, 0, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 0, 1, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 0, 0, 1]), tensor([1, 0, 0, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([0, 1, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([0, 0, 1, 0, 0]), tensor([1, 0, 0, 0, 0]), tensor([1, 0, 0, 0, 0])]\n"
     ]
    }
   ],
   "source": [
    "features_train['labels'] = [label for label in y_train]\n",
    "features_test['labels'] = [label for label in y_test]\n",
    "\n",
    "print(features_train['labels'][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_values': tensor([-2.5145, -2.6991, -2.9758,  ..., -1.0219, -0.8769, -0.7451]), 'labels': tensor([[1., 0., 0., 0., 0.]])}\n",
      "{'input_values': tensor([-0.1155, -0.0957, -0.2171,  ...,  0.4292,  0.2699,  0.0196]), 'labels': tensor([[1., 0., 0., 0., 0.]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_20288\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_values = torch.tensor(self.encodings['input_values'][idx], dtype=torch.float)\n",
    "        labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n",
    "        return {'input_values': input_values, 'labels': labels}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_values'])\n",
    "\n",
    "    \n",
    "train_dataset = Dataset(features_train)\n",
    "test_dataset = Dataset(features_test)\n",
    "\n",
    "print(train_dataset[9])\n",
    "print(test_dataset[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3226 807\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training input_values: tensor([-0.1209, -0.1384, -0.0683,  ..., -0.4570, -0.4188, -0.3885])\n",
      "Training labels: tensor([[1., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_20288\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training input_values: {train_dataset[0]['input_values']}\")\n",
    "print(f\"Training labels: {train_dataset[0]['labels']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "class HubertForMulticlassClassification(nn.Module):\n",
    "    def __init__(self, hubert_model_name='facebook/hubert-base-ls960', num_classes=5):\n",
    "        super(HubertForMulticlassClassification, self).__init__()\n",
    "        self.feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(hubert_model_name)\n",
    "        self.hubert = HubertModel.from_pretrained(hubert_model_name)\n",
    "        self.classifier = nn.Linear(self.hubert.config.hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, input_values):\n",
    "        outputs = self.hubert(input_values).last_hidden_state\n",
    "        # Use the mean of the last hidden state as the input to the classifier\n",
    "        mean_output = torch.mean(outputs, dim=1)\n",
    "        logits = self.classifier(mean_output)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\envs\\labplnta\\lib\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HubertForMulticlassClassification(\n",
       "  (hubert): HubertModel(\n",
       "    (feature_extractor): HubertFeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): HubertGroupNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "          (layer_norm): GroupNorm(512, 512, eps=1e-05, affine=True)\n",
       "        )\n",
       "        (1-4): 4 x HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x HubertNoLayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,), bias=False)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): HubertFeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=768, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): HubertEncoder(\n",
       "      (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          768, 768, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): HubertSamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x HubertEncoderLayer(\n",
       "          (attention): HubertAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): HubertFeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "model = HubertForMulticlassClassification(num_classes=5)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter('runs/hubert_depression_multiclass_experiment_4_cata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, criterion, device, writer, epoch):\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        input_values = batch['input_values'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # print(input_values.shape)\n",
    "        # print(labels.shape)\n",
    "        \n",
    "        labels = labels.squeeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_values)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # break\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Log training loss\n",
    "        if batch_idx % 10 == 0:  # Log every 10 batches\n",
    "            writer.add_scalar('Training Loss', loss.item(), epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    return avg_loss\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device, writer, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            input_values = batch['input_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            labels = labels.squeeze(1)\n",
    "            \n",
    "           \n",
    "            labels = torch.argmax(labels, axis=1)\n",
    "            # print(\"LABEL: \", labels)\n",
    "            outputs = model(input_values)\n",
    "            # print(\"OUTPUT: \", outputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(torch.argmax(outputs, axis=1).cpu().numpy())\n",
    "            # print(\"PREDICTION: \", torch.argmax(outputs, axis=1).cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    # Log validation metrics\n",
    "    writer.add_scalar('Validation Loss', avg_loss, epoch)\n",
    "    writer.add_scalar('Validation Accuracy', accuracy, epoch)\n",
    "    writer.add_scalar('Validation Precision', precision, epoch)\n",
    "    writer.add_scalar('Validation Recall', recall, epoch)\n",
    "    writer.add_scalar('Validation F1 Score', f1, epoch)\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall, f1\n",
    "\n",
    "def save_model(model, optimizer, epoch, model_path):\n",
    "    if not os.path.exists(model_path):\n",
    "        os.makedirs(model_path)\n",
    "    model_save_path = os.path.join(model_path, f'model_epoch_{epoch}.pth')\n",
    "    optimizer_save_path = os.path.join(model_path, f'optimizer_epoch_{epoch}.pth')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    torch.save(optimizer.state_dict(), optimizer_save_path)\n",
    "    print(f\"Model and optimizer saved to {model_save_path} and {optimizer_save_path}\")\n",
    "\n",
    "def load_model(model_path, epoch):\n",
    "    model = HubertForMulticlassClassification()\n",
    "    model_load_path = os.path.join(model_path, f'model_epoch_{epoch}.pth')\n",
    "    optimizer_load_path = os.path.join(model_path, f'optimizer_epoch_{epoch}.pth')\n",
    "    model.load_state_dict(torch.load(model_load_path))\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "    optimizer.load_state_dict(torch.load(optimizer_load_path))\n",
    "    \n",
    "    model.to(device)\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n",
      "d:\\python\\envs\\labplnta\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Train Loss: 0.7331\n",
      "Validation Loss: 0.1081\n",
      "Accuracy: 0.9628, Precision: 0.9426, Recall: 0.9628, F1 Score: 0.9521\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_0.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "Train Loss: 0.2178\n",
      "Validation Loss: 0.0639\n",
      "Accuracy: 0.9777, Precision: 0.9781, Recall: 0.9777, F1 Score: 0.9754\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_1.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "Train Loss: 0.1607\n",
      "Validation Loss: 0.0355\n",
      "Accuracy: 0.9938, Precision: 0.9938, Recall: 0.9938, F1 Score: 0.9938\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_2.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "Train Loss: 0.1020\n",
      "Validation Loss: 0.0408\n",
      "Accuracy: 0.9888, Precision: 0.9889, Recall: 0.9888, F1 Score: 0.9888\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_3.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "Train Loss: 0.1000\n",
      "Validation Loss: 0.0414\n",
      "Accuracy: 0.9888, Precision: 0.9890, Recall: 0.9888, F1 Score: 0.9888\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_4.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "Train Loss: 0.0728\n",
      "Validation Loss: 0.1254\n",
      "Accuracy: 0.9715, Precision: 0.9731, Recall: 0.9715, F1 Score: 0.9717\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_5.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "Train Loss: 0.0928\n",
      "Validation Loss: 0.0374\n",
      "Accuracy: 0.9901, Precision: 0.9902, Recall: 0.9901, F1 Score: 0.9901\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_6.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_6.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "Train Loss: 0.0751\n",
      "Validation Loss: 0.0506\n",
      "Accuracy: 0.9827, Precision: 0.9828, Recall: 0.9827, F1 Score: 0.9817\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_7.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_7.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "Train Loss: 0.0428\n",
      "Validation Loss: 0.1342\n",
      "Accuracy: 0.9665, Precision: 0.9692, Recall: 0.9665, F1 Score: 0.9666\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_8.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_8.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_7336\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "Train Loss: 0.0486\n",
      "Validation Loss: 0.0585\n",
      "Accuracy: 0.9777, Precision: 0.9780, Recall: 0.9777, F1 Score: 0.9748\n",
      "Model and optimizer saved to ./hubert_depression_multiclass_model_cata\\model_epoch_9.pth and ./hubert_depression_multiclass_model_cata\\optimizer_epoch_9.pth\n"
     ]
    }
   ],
   "source": [
    "# Training and evaluation setup\n",
    "num_epochs = 10\n",
    "model_path = './hubert_depression_multiclass_model'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, device, writer, epoch)\n",
    "    val_loss, accuracy, precision, recall, f1 = evaluate(model, test_loader, criterion, device, writer, epoch)\n",
    "    # break\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Train Loss: {train_loss:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}')\n",
    "    print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "    \n",
    "    # Save the model after each epoch\n",
    "    save_model(model, optimizer, epoch, model_path)\n",
    "\n",
    "# Close the writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/hubert-base-ls960 were not used when initializing HubertModel: ['encoder.pos_conv_embed.conv.weight_g', 'encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing HubertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing HubertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of HubertModel were not initialized from the model checkpoint at facebook/hubert-base-ls960 and are newly initialized: ['encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\ramona\\AppData\\Local\\Temp\\ipykernel_20288\\3042093823.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(self.encodings['labels'][idx], dtype=torch.float).unsqueeze(0)  # Ensure labels are shaped correctly\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model and plot cmf\n",
    "model_path = './hubert_depression_multiclass_model_cata'\n",
    "model, optimizer = load_model(model_path, 2)\n",
    "# val_loss, accuracy, precision, recall, f1 = evaluate(model, test_loader, criterion, device, writer, 6)\n",
    "# print(f'Validation Loss: {val_loss:.4f}')\n",
    "# print(f'Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}')\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_confusion_matrix(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(test_loader):\n",
    "            input_values = batch['input_values'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            labels = labels.squeeze(1)\n",
    "            \n",
    "            labels = torch.argmax(labels, axis=1)\n",
    "            outputs = model(input_values)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(torch.argmax(outputs, axis=1).cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "plot_confusion_matrix(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cm = confusion_matrix(all_labels, all_preds)\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n",
    "# plt.xlabel('Predicted labels')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.ylabel('True labels')\n",
    "# plt.show()\n",
    "# plot_confusion_matrix(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labplnta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
